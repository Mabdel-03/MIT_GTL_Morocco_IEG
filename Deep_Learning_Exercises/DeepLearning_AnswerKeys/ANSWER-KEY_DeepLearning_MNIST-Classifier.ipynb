{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyPq6xxhTj33MQzmpHKkt1zu"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":[],"metadata":{"id":"E4wILs-j9-cO"}},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Dj_MiI4O99YZ","executionInfo":{"status":"ok","timestamp":1737532270105,"user_tz":-60,"elapsed":308940,"user":{"displayName":"Mahmoud Abdelmoneum","userId":"17397917820603661988"}},"outputId":"322e8575-0c4b-4000-92ba-742750a8b3ad"},"outputs":[{"output_type":"stream","name":"stdout","text":["Training MLP...\n","Epoch [1/10], Loss: 0.3978\n","Epoch [2/10], Loss: 0.2167\n","Epoch [3/10], Loss: 0.1776\n","Epoch [4/10], Loss: 0.1597\n","Epoch [5/10], Loss: 0.1463\n","Epoch [6/10], Loss: 0.1381\n","Epoch [7/10], Loss: 0.1262\n","Epoch [8/10], Loss: 0.1214\n","Epoch [9/10], Loss: 0.1182\n","Epoch [10/10], Loss: 0.1110\n","Testing MLP...\n","Test Accuracy: 97.25%\n","Training CNN...\n","Epoch [1/10], Loss: 0.2340\n","Epoch [2/10], Loss: 0.0892\n","Epoch [3/10], Loss: 0.0677\n","Epoch [4/10], Loss: 0.0543\n","Epoch [5/10], Loss: 0.0470\n","Epoch [6/10], Loss: 0.0383\n","Epoch [7/10], Loss: 0.0360\n","Epoch [8/10], Loss: 0.0312\n","Epoch [9/10], Loss: 0.0275\n","Epoch [10/10], Loss: 0.0265\n","Testing CNN...\n","Test Accuracy: 99.14%\n","Comparison:\n","MLP Test Accuracy: 97.25%\n","CNN Test Accuracy: 99.14%\n"]}],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torchvision import datasets, transforms\n","from torch.utils.data import DataLoader\n","import matplotlib.pyplot as plt\n","\n","# Device configuration\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","# Load MNIST dataset\n","transform = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.5,), (0.5,))\n","])\n","\n","train_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n","test_dataset = datasets.MNIST(root='./data', train=False, transform=transform, download=True)\n","\n","train_loader = DataLoader(dataset=train_dataset, batch_size=32, shuffle=True)\n","test_loader = DataLoader(dataset=test_dataset, batch_size=32, shuffle=False)\n","\n","# Define MLP model\n","class MLP(nn.Module):\n","    def __init__(self):\n","        super(MLP, self).__init__()\n","        self.model = nn.Sequential(\n","            nn.Flatten(),\n","            nn.Linear(28*28, 128),\n","            nn.ReLU(),\n","            nn.Dropout(0.2),\n","            nn.Linear(128, 64),\n","            nn.ReLU(),\n","            nn.Linear(64, 10)\n","        )\n","\n","    def forward(self, x):\n","        return self.model(x)\n","\n","# Define CNN model\n","class CNN(nn.Module):\n","    def __init__(self):\n","        super(CNN, self).__init__()\n","        self.model = nn.Sequential(\n","            nn.Conv2d(1, 32, kernel_size=3),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2),\n","            nn.Conv2d(32, 64, kernel_size=3),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2),\n","            nn.Flatten(),\n","            nn.Linear(64*5*5, 128),\n","            nn.ReLU(),\n","            nn.Dropout(0.5),\n","            nn.Linear(128, 10)\n","        )\n","\n","    def forward(self, x):\n","        return self.model(x)\n","\n","# Training function\n","def train_model(model, train_loader, criterion, optimizer, num_epochs):\n","    model.train()\n","    for epoch in range(num_epochs):\n","        running_loss = 0.0\n","        for images, labels in train_loader:\n","            images, labels = images.to(device), labels.to(device)\n","\n","            # Forward pass\n","            outputs = model(images)\n","            loss = criterion(outputs, labels)\n","\n","            # Backward pass and optimization\n","            optimizer.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","\n","            running_loss += loss.item()\n","\n","        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}\")\n","\n","# Testing function\n","def test_model(model, test_loader):\n","    model.eval()\n","    correct = 0\n","    total = 0\n","    with torch.no_grad():\n","        for images, labels in test_loader:\n","            images, labels = images.to(device), labels.to(device)\n","            outputs = model(images)\n","            _, predicted = torch.max(outputs, 1)\n","            total += labels.size(0)\n","            correct += (predicted == labels).sum().item()\n","\n","    accuracy = 100 * correct / total\n","    print(f\"Test Accuracy: {accuracy:.2f}%\")\n","    return accuracy\n","\n","# Instantiate and train MLP\n","print(\"Training MLP...\")\n","mlp_model = MLP().to(device)\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(mlp_model.parameters(), lr=0.001)\n","train_model(mlp_model, train_loader, criterion, optimizer, num_epochs=10)\n","print(\"Testing MLP...\")\n","mlp_accuracy = test_model(mlp_model, test_loader)\n","\n","# Instantiate and train CNN\n","print(\"Training CNN...\")\n","cnn_model = CNN().to(device)\n","optimizer = optim.Adam(cnn_model.parameters(), lr=0.001)\n","train_model(cnn_model, train_loader, criterion, optimizer, num_epochs=10)\n","print(\"Testing CNN...\")\n","cnn_accuracy = test_model(cnn_model, test_loader)\n","\n","# Compare performances\n","print(\"Comparison:\")\n","print(f\"MLP Test Accuracy: {mlp_accuracy:.2f}%\")\n","print(f\"CNN Test Accuracy: {cnn_accuracy:.2f}%\")\n"]},{"cell_type":"code","source":[],"metadata":{"id":"e4DZseYZ-MYN"},"execution_count":null,"outputs":[]}]}